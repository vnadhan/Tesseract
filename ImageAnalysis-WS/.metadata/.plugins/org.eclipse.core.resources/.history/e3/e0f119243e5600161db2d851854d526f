import java.io.File;

import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.opencv_core.CvSeq;
import org.bytedeco.javacpp.opencv_core.IplImage;
import org.bytedeco.javacv.Frame;
import org.bytedeco.javacv.OpenCVFrameConverter;
import org.bytedeco.javacv.cvkernels;
import org.junit.Test;

import static org.bytedeco.javacpp.tesseract.*;
import static org.junit.Assert.assertTrue;
import static org.bytedeco.javacpp.opencv_imgcodecs.*;
import static org.bytedeco.javacpp.opencv_highgui.*;
import static org.bytedeco.javacpp.opencv_core.*;
import static org.bytedeco.javacpp.opencv_imgproc.*;

public class BasicTesseractExampleTest {
    
	
//    @Test
//    public void givenTessBaseApi_whenImageOcrd_thenTextDisplayed() throws Exception {
//        BytePointer outText;
//
//        TessBaseAPI api = new TessBaseAPI();
//        // Initialize tesseract-ocr with English, without specifying tessdata path
//        if (api.Init(".", "ENG") != 0) {
//            System.err.println("Could not initialize tesseract.");
//            System.exit(1);
//        }
//
//        // Open input image with leptonica library
//        PIX image = pixRead("vishnu.png");
//        api.SetImage(image);
//        // need to process the image
//        api.SetSourceResolution(442);
//        
//        // Get OCR result
//        outText = api.GetUTF8Text();
//        
//        String string = outText.getString();
//        assertTrue(!string.isEmpty());
//        System.out.println("GetUTF8Text output:\n" + string);
//        System.out.println("------------------------------------------------------------------------");
//        //System.out.println("GetUNLVText output:\n" + api.GetUNLVText());
//        // Destroy used object and release memory
//        api.End();
//        outText.deallocate();
//        pixDestroy(image);
//    }
	
	private IplImage downScaleImage(IplImage srcImage, int percent) {
		System.out.println("srcImage : " + srcImage.height() + " - " + srcImage.width());
		
		IplImage destImage = cvCreateImage(cvSize((srcImage.width()*percent)/100, (srcImage.height()*percent)/100), srcImage.depth(), srcImage.nChannels());
		
		cvResize(srcImage, destImage);
		
		return destImage;
		
	}
	
	private IplImage applyEdgeDetection(IplImage srcImage, int percent) {
		IplImage destImage = downScaleImage(srcImage, percent);
		
		IplImage grayImage = cvCreateImage(cvGetSize(destImage), IPL_DEPTH_8U, 1);
		
		cvCvtColor(destImage, grayImage, CV_BGR2GRAY);
		
		OpenCVFrameConverter.ToMat converterToMat = new OpenCVFrameConverter.ToMat();
		Frame grayImageFrame = converterToMat.convert(grayImage);
		Mat grayImageMat = converterToMat.convert(grayImageFrame);
		
		GaussianBlur(grayImageMat, grayImageMat, new Size(5, 5), 0.0, 0.0, BORDER_DEFAULT);
		
		destImage = converterToMat.convertToIplImage(grayImageFrame);
		
		
		cvErode(destImage, destImage);
		cvDilate(destImage, destImage);
	
		cvCanny(destImage, destImage, 75.0, 200.0);
		System.out.println("done");
		cvSaveImage("abc-cannyedgedetection.jpg", destImage);
		
		//cvReleaseImage(destImage);
		
		System.out.println("done");
		return destImage;
	}
	
	private CvSeq findLargestSquareOnCanyDetectedImage(IplImage cannyEdgeDetectedImage) {
		IplImage foundedCountoursImage = cvCloneImage(cannyEdgeDetectedImage);
		CvMemStorage memory = CvMemStorage.create();
		CvSeq contours = new CvSeq();
		cvFindContours(foundedCountoursImage, memory, contours, Loader.sizeof(CvContour.class), CV_RETR_LIST, CV_CHAIN_APPROX_SIMPLE
				, cvPoint(0,0));
		
		int maxWidth = 0;
		int maxHeight = 0;
		CvRect contour = null;
		CvSeq seqFounded = null;
		CvSeq nextSeq = new CvSeq();
		
		for(nextSeq = contours; nextSeq != null; nextSeq = nextSeq.h_next()) {
			contour = cvBoundingRect(nextSeq, 0);
			if(contour.width() >= maxWidth && contour.height() >= maxHeight) {
				maxWidth = contour.width();
				maxHeight = contour.height();
				seqFounded = nextSeq;
			}
		}
		CvSeq result = cvApproxPoly(seqFounded, Loader.sizeof(CvContour.class), memory, CV_POLY_APPROX_DP, cvContourPerimeter(seqFounded)*0.02,0);
		
		for(int i = 0; i<result.total();i++){
			CvPoint v = new CvPoint(cvGetSeqElem(result,i));
			cvDrawCircle(foundedCountoursImage, v, 5, CvScalar.BLUE, 20, 8, 0);
			System.out.println("found point");
		}
		cvSaveImage("abc-contours.jpg", foundedCountoursImage);
		return result;
	}
	
	@Test
    public void givenTessBaseApi_whenImageOcrd_thenTextDisplayed() throws Exception {
        BytePointer outText;

        TessBaseAPI api = new TessBaseAPI();
        // Initialize tesseract-ocr with English, without specifying tessdata path
        if (api.Init(".", "ENG") != 0) {
            System.err.println("Could not initialize tesseract.");
            System.exit(1);
        }
        //System.out.println();
        
        IplImage img = cvLoadImage("bill.jpg");
        System.out.println(img.width() + "- " + img.height());
        
        findLargestSquareOnCanyDetectedImage(applyEdgeDetection(downScaleImage(img, 100), 100));
        
        
        // Open input image with leptonica library
        //PIX image = pixRead();
       // api.SetImage(image);
        // need to process the image
//        api.SetSourceResolution(442);
//        
//        // Get OCR result
//        outText = api.GetUTF8Text();
//        
//        String string = outText.getString();
//        assertTrue(!string.isEmpty());
//        System.out.println("GetUTF8Text output:\n" + string);
//        System.out.println("------------------------------------------------------------------------");
//        //System.out.println("GetUNLVText output:\n" + api.GetUNLVText());
//        // Destroy used object and release memory
//        api.End();
//        outText.deallocate();
//        pixDestroy(image);
    }
}